{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1688a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22acf933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 4898\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.0              0.27         0.36            20.7      0.045   \n",
      "1            6.3              0.30         0.34             1.6      0.049   \n",
      "2            8.1              0.28         0.40             6.9      0.050   \n",
      "3            7.2              0.23         0.32             8.5      0.058   \n",
      "4            7.2              0.23         0.32             8.5      0.058   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
      "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
      "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
      "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      8.8        0  \n",
      "1      9.5        0  \n",
      "2     10.1        0  \n",
      "3      9.9        0  \n",
      "4      9.9        0  \n"
     ]
    }
   ],
   "source": [
    "fname = os.path.join(os.getcwd() + \"/Assignment1/code/\", \"wine-dataset.csv\")\n",
    "# with open(file_name) as f:\n",
    "#     next(f, None)\n",
    "#     data = [tuple(line) for line in csv.reader(f, delimiter=\",\")]\n",
    "df = pd.read_csv(fname)\n",
    "print(\"Number of records: %d\" % len(df))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d11817c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3838\n",
      "1    1060\n",
      "Name: quality, dtype: int64\n",
      "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
      "count    4898.000000       4898.000000  4898.000000     4898.000000   \n",
      "mean        6.854788          0.278241     0.334192        6.391415   \n",
      "std         0.843868          0.100795     0.121020        5.072058   \n",
      "min         3.800000          0.080000     0.000000        0.600000   \n",
      "25%         6.300000          0.210000     0.270000        1.700000   \n",
      "50%         6.800000          0.260000     0.320000        5.200000   \n",
      "75%         7.300000          0.320000     0.390000        9.900000   \n",
      "max        14.200000          1.100000     1.660000       65.800000   \n",
      "\n",
      "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
      "count  4898.000000          4898.000000           4898.000000  4898.000000   \n",
      "mean      0.045772            35.308085            138.360657     0.994027   \n",
      "std       0.021848            17.007137             42.498065     0.002991   \n",
      "min       0.009000             2.000000              9.000000     0.987110   \n",
      "25%       0.036000            23.000000            108.000000     0.991723   \n",
      "50%       0.043000            34.000000            134.000000     0.993740   \n",
      "75%       0.050000            46.000000            167.000000     0.996100   \n",
      "max       0.346000           289.000000            440.000000     1.038980   \n",
      "\n",
      "                pH    sulphates      alcohol      quality  \n",
      "count  4898.000000  4898.000000  4898.000000  4898.000000  \n",
      "mean      3.188267     0.489847    10.514267     0.216415  \n",
      "std       0.151001     0.114126     1.230621     0.411842  \n",
      "min       2.720000     0.220000     8.000000     0.000000  \n",
      "25%       3.090000     0.410000     9.500000     0.000000  \n",
      "50%       3.180000     0.470000    10.400000     0.000000  \n",
      "75%       3.280000     0.550000    11.400000     0.000000  \n",
      "max       3.820000     1.080000    14.200000     1.000000  \n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0       0.307692          0.186275     0.216867        0.308282   0.106825   \n",
      "1       0.240385          0.215686     0.204819        0.015337   0.118694   \n",
      "2       0.413462          0.196078     0.240964        0.096626   0.121662   \n",
      "3       0.326923          0.147059     0.192771        0.121166   0.145401   \n",
      "4       0.326923          0.147059     0.192771        0.121166   0.145401   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
      "0             0.149826              0.373550  0.267785  0.254545   0.267442   \n",
      "1             0.041812              0.285383  0.132832  0.527273   0.313953   \n",
      "2             0.097561              0.204176  0.154039  0.490909   0.255814   \n",
      "3             0.156794              0.410673  0.163678  0.427273   0.209302   \n",
      "4             0.156794              0.410673  0.163678  0.427273   0.209302   \n",
      "\n",
      "    alcohol  quality  \n",
      "0  0.129032      0.0  \n",
      "1  0.241935      0.0  \n",
      "2  0.338710      0.0  \n",
      "3  0.306452      0.0  \n",
      "4  0.306452      0.0  \n"
     ]
    }
   ],
   "source": [
    "def class_counts(rows):\n",
    "    \"\"\"Counts the number of each type of example in a dataset.\"\"\"\n",
    "    counts = {}  # a dictionary of label -> count.\n",
    "    for row in rows:\n",
    "        # in our dataset format, the label is always the last column\n",
    "        label = row[-1]\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts\n",
    "print(df['quality'].value_counts())\n",
    "print(df.describe())\n",
    "df.isnull().sum()\n",
    "normalized_df=(df - df.min())/(df.max() - df.min())\n",
    "print(normalized_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98ae6fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    \"\"\"A Question is used to partition a dataset.\n",
    "\n",
    "    This class just records a 'column number' (e.g., 0 for Color) and a\n",
    "    'column value' (e.g., Green). The 'match' method is used to compare\n",
    "    the feature value in an example to the feature value stored in the\n",
    "    question. See the demo below.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "\n",
    "    def match(self, example):\n",
    "        # Compare the feature value in an example to the\n",
    "        # feature value in this question.\n",
    "        val = example[self.column]\n",
    "        if is_numeric(val):\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "\n",
    "    def __repr__(self):\n",
    "        # This is just a helper method to print\n",
    "        # the question in a readable format.\n",
    "        condition = \"==\"\n",
    "        if is_numeric(self.value):\n",
    "            condition = \">=\"\n",
    "        return \"Is %s %s %s?\" % (\n",
    "            header[self.column], condition, str(self.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4a79895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(column):\n",
    "    \"\"\"\n",
    "    Calculate entropy given a pandas series, list, or numpy array.\n",
    "    \"\"\"\n",
    "    # Compute the counts of each unique value in the column\n",
    "    counts = np.bincount(column)\n",
    "    # Divide by the total column length to get a probability\n",
    "    probabilities = counts / len(column)\n",
    "    \n",
    "    # Initialize the entropy to 0\n",
    "    entropy = 0\n",
    "    # Loop through the probabilities, and add each one to the total entropy\n",
    "    for prob in probabilities:\n",
    "        if prob > 0:\n",
    "            # use log from math and set base to 2\n",
    "            entropy += prob * math.log(prob, 2)\n",
    "    \n",
    "    return -entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19d6d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_information_gain(data, split_name, target_name):\n",
    "    \"\"\"\n",
    "    Calculate information gain given a data set, column to split on, and target\n",
    "    \"\"\"\n",
    "    # Calculate the original entropy\n",
    "    original_entropy = calc_entropy(data[target_name])\n",
    "    \n",
    "    #Find the unique values in the column\n",
    "    values = data[split_name].unique()\n",
    "    \n",
    "    \n",
    "    # Make two subsets of the data, based on the unique values\n",
    "    left_split = data[data[split_name] == values[0]]\n",
    "    right_split = data[data[split_name] == values[1]]\n",
    "    \n",
    "    # Loop through the splits and calculate the subset entropies\n",
    "    to_subtract = 0\n",
    "    for subset in [left_split, right_split]:\n",
    "        prob = (subset.shape[0] / data.shape[0]) \n",
    "        to_subtract += prob * calc_entropy(subset[target_name])\n",
    "    \n",
    "    # Return information gain\n",
    "    return original_entropy - to_subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9df6e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_info_gain(columns):\n",
    "  #Intialize an empty dictionary for information gains\n",
    "  information_gains = {}\n",
    "  \n",
    "  #Iterate through each column name in our list\n",
    "  for col in columns:\n",
    "    #Find the information gain for the column\n",
    "    information_gain = calc_information_gain(midwest, col, 'midwest?')\n",
    "    #Add the information gain to our dictionary using the column name as the ekey                                         \n",
    "    information_gains[col] = information_gain\n",
    "  \n",
    "  #Return the key with the highest value                                          \n",
    "  return max(information_gains, key=information_gains.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7917512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(rows, question):\n",
    "    \"\"\"Partitions a dataset.\n",
    "\n",
    "    For each row in the dataset, check if it matches the question. If\n",
    "    so, add it to 'true rows', otherwise, add it to 'false rows'.\n",
    "    \"\"\"\n",
    "    true_rows, false_rows = [], []\n",
    "    for row in rows:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "827be4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(rows):\n",
    "    \"\"\"Calculate the Gini Impurity for a list of rows.\n",
    "\n",
    "    There are a few different ways to do this, I thought this one was\n",
    "    the most concise. See:\n",
    "    https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
    "    \"\"\"\n",
    "    \n",
    "    counts = class_counts(rows)\n",
    "    impurity = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "        impurity -= prob_of_lbl**2\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8987c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left, right, current_uncertainty):\n",
    "    \"\"\"Information Gain.\n",
    "\n",
    "    The uncertainty of the starting node, minus the weighted impurity of\n",
    "    two child nodes.\n",
    "    \"\"\"\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_uncertainty - p * gini(left) - (1 - p) * gini(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0cf5d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(rows):\n",
    "    \"\"\"Find the best question to ask by iterating over every feature / value\n",
    "    and calculating the information gain.\"\"\"\n",
    "    best_gain = 0  # keep track of the best information gain\n",
    "    best_question = None  # keep train of the feature / value that produced it\n",
    "    current_uncertainty = gini(rows)\n",
    "    n_features = len(rows[0]) - 1  # number of columns\n",
    "\n",
    "    for col in range(n_features):  # for each feature\n",
    "\n",
    "        values = set([row[col] for row in rows])  # unique values in the column\n",
    "\n",
    "        for val in values:  # for each value\n",
    "\n",
    "            question = Question(col, val)\n",
    "\n",
    "            # try splitting the dataset\n",
    "            true_rows, false_rows = partition(rows, question)\n",
    "\n",
    "            # Skip this split if it doesn't divide the\n",
    "            # dataset.\n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "\n",
    "            # Calculate the information gain from this split\n",
    "            gain = info_gain(true_rows, false_rows, current_uncertainty)\n",
    "\n",
    "            # You actually can use '>' instead of '>=' here\n",
    "            # but I wanted the tree to look a certain way for our\n",
    "            # toy dataset.\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "\n",
    "    return best_gain, best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "099ac028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    \"\"\"A Leaf node classifies data.\n",
    "\n",
    "    This holds a dictionary of class (e.g., \"Apple\") -> number of times\n",
    "    it appears in the rows from the training data that reach this leaf.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rows):\n",
    "        self.predictions = class_counts(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50ef72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    tree = {}\n",
    "\n",
    "    def learn(self, training_set):\n",
    "        # implement this function\n",
    "        self.tree = {}\n",
    "        \"\"\"Builds the tree.\n",
    "\n",
    "        Rules of recursion: 1) Believe that it works. 2) Start by checking\n",
    "        for the base case (no further information gain). 3) Prepare for\n",
    "        giant stack traces.\n",
    "        \"\"\"\n",
    "\n",
    "        # Try partitioing the dataset on each of the unique attribute,\n",
    "        # calculate the information gain,\n",
    "        # and return the question that produces the highest gain.\n",
    "        gain, question = find_best_split(rows)\n",
    "\n",
    "        # Base case: no further info gain\n",
    "        # Since we can ask no further questions,\n",
    "        # we'll return a leaf.\n",
    "        if gain == 0:\n",
    "            return Leaf(rows)\n",
    "\n",
    "        # If we reach here, we have found a useful feature / value\n",
    "        # to partition on.\n",
    "        true_rows, false_rows = partition(rows, question)\n",
    "\n",
    "        # Recursively build the true branch.\n",
    "        true_branch = build_tree(true_rows)\n",
    "\n",
    "        # Recursively build the false branch.\n",
    "        false_branch = build_tree(false_rows)\n",
    "\n",
    "        # Return a Question node.\n",
    "        # This records the best feature / value to ask at this point,\n",
    "        # as well as the branches to follow\n",
    "        # dependingo on the answer.\n",
    "        return Decision_Node(question, true_branch, false_branch)\n",
    "\n",
    "    # implement this function\n",
    "    def classify(self, test_instance):\n",
    "        result = 0 # baseline: always classifies as 0\n",
    "        # Base case: we've reached a leaf\n",
    "        if isinstance(node, Leaf):\n",
    "            return node.predictions\n",
    "\n",
    "        # Decide whether to follow the true-branch or the false-branch.\n",
    "        # Compare the feature / value stored in the node,\n",
    "        # to the example we're considering.\n",
    "        if node.question.match(row):\n",
    "            result = classify(row, node.true_branch)\n",
    "        else:\n",
    "            result = classify(row, node.false_branch)\n",
    "        total = sum(result.values()) * 1.0\n",
    "        probs = {}\n",
    "        for lbl in result.keys():\n",
    "            probs[lbl] = int(result[lbl] / total * 100)\n",
    "        \n",
    "        return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13488081",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Node:\n",
    "    \"\"\"A Decision Node asks a question.\n",
    "\n",
    "    This holds a reference to the question, and to the two child nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 question,\n",
    "                 true_branch,\n",
    "                 false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a56b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
